{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1LOuuQaT4PTp","executionInfo":{"status":"ok","timestamp":1699636121739,"user_tz":300,"elapsed":4582,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np"]},{"cell_type":"code","source":["!pip install keras_nlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"999vWH_TNSos","executionInfo":{"status":"ok","timestamp":1699636142131,"user_tz":300,"elapsed":7448,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"19aba968-3e42-48a9-afec-3230808215d4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras_nlp\n","  Downloading keras_nlp-0.6.3-py3-none-any.whl (584 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/584.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/584.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-core (from keras_nlp)\n","  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (23.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2023.6.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (13.6.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.8)\n","Collecting tensorflow-text (from keras_nlp)\n","  Downloading tensorflow_text-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting namex (from keras-core->keras_nlp)\n","  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (3.9.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (2.16.1)\n","Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (0.15.0)\n","Requirement already satisfied: tensorflow<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (2.14.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (16.0.6)\n","Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (1.59.2)\n","Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2.14.0)\n","Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (0.41.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow-text->keras_nlp) (3.2.2)\n","Installing collected packages: namex, keras-core, tensorflow-text, keras_nlp\n","Successfully installed keras-core-0.1.7 keras_nlp-0.6.3 namex-0.0.7 tensorflow-text-2.14.0\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LZhG3304cwg","outputId":"651227f0-dc4d-477e-89b8-600ff627bce7","executionInfo":{"status":"ok","timestamp":1699636216627,"user_tz":300,"elapsed":672,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using TensorFlow backend\n"]}],"source":["import keras_nlp"]},{"cell_type":"code","source":["!wget http://nlp.uoregon.edu/download/embeddings/glove.6B.50d.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9vJYmv3Np76","executionInfo":{"status":"ok","timestamp":1699636245994,"user_tz":300,"elapsed":1805,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"46a50f6f-3228-4a1f-bfb4-e758c09b280e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-10 17:10:44--  http://nlp.uoregon.edu/download/embeddings/glove.6B.50d.txt\n","Resolving nlp.uoregon.edu (nlp.uoregon.edu)... 128.223.8.161, 2607:8400:205e:8:ae1f:6bff:fe93:6364\n","Connecting to nlp.uoregon.edu (nlp.uoregon.edu)|128.223.8.161|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 171350079 (163M) [text/plain]\n","Saving to: ‘glove.6B.50d.txt’\n","\n","glove.6B.50d.txt    100%[===================>] 163.41M   105MB/s    in 1.6s    \n","\n","2023-11-10 17:10:45 (105 MB/s) - ‘glove.6B.50d.txt’ saved [171350079/171350079]\n","\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7gmaZiwe5qMY","executionInfo":{"status":"ok","timestamp":1699636263219,"user_tz":300,"elapsed":6550,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[],"source":["embeddings_index = {}\n","\n","with open('glove.6B.50d.txt') as f:\n","  for line in f:\n","    word, coefs = line.split(maxsplit=1)\n","    coefs = np.fromstring(coefs, \"f\", sep = ' ')\n","    embeddings_index[word] = coefs"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wwGlpln6THS","outputId":"b0fba540-c1b9-447b-f2e3-f40fcadd5fef","executionInfo":{"status":"ok","timestamp":1699636263219,"user_tz":300,"elapsed":24,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.30824 ,  0.17223 , -0.23339 ,  0.023105,  0.28522 ,  0.23076 ,\n","       -0.41048 , -1.0035  , -0.2072  ,  1.4327  , -0.80684 ,  0.68954 ,\n","       -0.43648 ,  1.1069  ,  1.6107  , -0.31966 ,  0.47744 ,  0.79395 ,\n","       -0.84374 ,  0.064509,  0.90251 ,  0.78609 ,  0.29699 ,  0.76057 ,\n","        0.433   , -1.5032  , -1.6423  ,  0.30256 ,  0.30771 , -0.87057 ,\n","        2.4782  , -0.025852,  0.5013  , -0.38593 , -0.15633 ,  0.45522 ,\n","        0.04901 , -0.42599 , -0.86402 , -1.3076  , -0.29576 ,  1.209   ,\n","       -0.3127  , -0.72462 , -0.80801 ,  0.082667,  0.26738 , -0.98177 ,\n","       -0.32147 ,  0.99823 ], dtype=float32)"]},"metadata":{},"execution_count":9}],"source":["embeddings_index ['movie']"]},{"cell_type":"markdown","metadata":{"id":"snL-KTLE6eN3"},"source":["# Get the movie data"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-LFLlyur6hnS","outputId":"3cc1bcdb-cfb1-4989-c10f-829357910ad5","executionInfo":{"status":"ok","timestamp":1699636266993,"user_tz":300,"elapsed":3795,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n"]}],"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000, maxlen=250)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"8Itbnb6262XS","executionInfo":{"status":"ok","timestamp":1699636266993,"user_tz":300,"elapsed":3,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[],"source":["x_all = np.append(x_train, x_test)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"NQFseWjD66vH","executionInfo":{"status":"ok","timestamp":1699636268141,"user_tz":300,"elapsed":1150,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[],"source":["x_all_padded = tf.keras.utils.pad_sequences(x_all, padding = \"post\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ipdIoHC77DTb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699636268141,"user_tz":300,"elapsed":19,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"347cde82-c94a-4548-f301-514babda3c4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1641221/1641221 [==============================] - 0s 0us/step\n"]}],"source":["word_lookup = tf.keras.datasets.imdb.get_word_index()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"gjPVJZOw7pjX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699636268141,"user_tz":300,"elapsed":17,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"336d58d7-31fb-4abb-f4f0-28316b03dcab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["17"]},"metadata":{},"execution_count":14}],"source":["word_lookup['movie']"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"gRNBiuuD7tpT","executionInfo":{"status":"ok","timestamp":1699636268429,"user_tz":300,"elapsed":304,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[],"source":["inverted_word_lookup = dict((index +3, word) for (word, index) in word_lookup.items())\n","\n","inverted_word_lookup[0] = \"[PAD]\"\n","inverted_word_lookup[1] = \"[START]\"\n","inverted_word_lookup[2] = \"[OOV]\"\n","inverted_word_lookup[3] = \"[NA]\""]},{"cell_type":"code","execution_count":27,"metadata":{"id":"v2MQ_jk4NNXr","executionInfo":{"status":"ok","timestamp":1699636975253,"user_tz":300,"elapsed":156,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[],"source":["def decode(x):\n","    return \" \".join(inverted_word_lookup[i] for i in x)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"yjX9YL1DNNXr","executionInfo":{"status":"ok","timestamp":1699636268429,"user_tz":300,"elapsed":10,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"01932e15-b0c4-40f3-b9b8-145f27d76d4f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"[START]theviewerleaveswonderingwhyhebotheredtowatchthisoneorwhyforthatmatteranyonebotheredtomakeitthereisnoplotjustrandomscenesofridiculousaction[OOV][OOV]showersceneappealstothemale[OOV]butthat'snotmuchreasontomakeamovie\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["decode(x_all[1000])"]},{"cell_type":"markdown","metadata":{"id":"cU8XW4gwNNXr"},"source":["## Build embedding model"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ny_ywZMvNNXs","executionInfo":{"status":"ok","timestamp":1699636268429,"user_tz":300,"elapsed":8,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"feec220a-3501-47dd-d4eb-56581f2739f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["else's\n","miyazaki's\n","victoria's\n","paul's\n","chan's\n","show's\n","wife's\n","character's\n","hadn't\n","isn't\n","haven't\n","wouldn't\n","its'\n","she'd\n","she's\n","paperhouse\n","they'll\n","it's\n","it'd\n","daughter's\n","ted's\n","ben's\n","america's\n","men's\n","he'll\n","john's\n","audience's\n","30's\n","mom's\n","hero's\n","hasn't\n","should've\n","imho\n","keaton's\n","they'd\n","zelah\n","you'll\n","smith's\n","girls'\n","craven's\n","feinstone\n","moore's\n","eastwood's\n","kids'\n","tv's\n","town's\n","anyone's\n","writer's\n","1960's\n","kubrick's\n","husband's\n","allen's\n","80's\n","stewart's\n","t'aime\n","boy's\n","man'\n","scott's\n","it´s\n","bakshi's\n","\n","\n","person's\n","you've\n","verhoeven's\n","spielberg's\n","it'll\n","carpenter's\n","life's\n","sister's\n","family's\n","who've\n","director's\n","where's\n","city's\n","author's\n","man's\n","friend's\n","we'd\n","would've\n","day's\n","freddy's\n","woman's\n","1930's\n","can't\n","ain't\n","actors'\n","90's\n","ossessione\n","ford's\n","couldn't\n","1990's\n","won't\n","that'll\n","other's\n","aren't\n","doctor's\n","everybody's\n","jackson's\n","we're\n","hollywood's\n","kelly's\n","david's\n","murphy's\n","dvd's\n","shakespeare's\n","characters'\n","mother's\n","he's\n","he'd\n","hitler's\n","everyone's\n","don't\n","could've\n","child's\n","miike's\n","simon's\n","children's\n","let's\n","didn't\n","you're\n","bug's\n","40's\n","someone's\n","today's\n","gypo\n","lynch's\n","1950's\n","palma's\n","michael's\n","girl's\n","killer's\n","50's\n","charlie's\n","you'd\n","doesn't\n","story's\n","i'd\n","i'm\n","they're\n","what's\n","devil's\n","1980's\n","rosemary's\n","\n","there's\n","world's\n","father's\n","wasn't\n","60's\n","carface\n","guy's\n","hartley's\n","wayne's\n","1970's\n","sinatra's\n","year's\n","god's\n","who's\n","who'd\n","'a\n","'i\n","film's\n","romero's\n","actor's\n","tony's\n","must've\n","jack's\n","people's\n","lee's\n","here's\n","that's\n","kid's\n","jones'\n","welles'\n","shouldn't\n","'the\n","one's\n","carlito's\n","che's\n","1940's\n","70's\n","altman's\n","we've\n","son's\n","they've\n","king's\n","jane's\n","we'll\n","disney's\n","hitchcock's\n","she'll\n","country's\n","i'll\n","harry's\n","movie's\n","weren't\n","women's\n","brother's\n","viewer's\n","branagh's\n","parents'\n","i've\n","[PAD]\n","[START]\n","[OOV]\n","[NA]\n","9797 hits, 207 misses\n"]}],"source":["embedding_matrix = np.zeros((10004, 50))\n","\n","hits = 0\n","misses = 0\n","\n","for i, word in inverted_word_lookup.items():\n","    if (i >= 10004):\n","        continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","        print(word)\n","\n","print(\"%d hits, %d misses\" % (hits, misses))"]},{"cell_type":"markdown","metadata":{"id":"Ml3mKA67NNXs"},"source":["### Create a decoder-only transformer"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njMHnSc7NNXs","executionInfo":{"status":"ok","timestamp":1699636275552,"user_tz":300,"elapsed":7127,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"482ec6d1-9a4e-4bf1-fff4-8eb57100de64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, None)]               0         []                            \n","                                                                                                  \n"," embedding (Embedding)       (None, None, 50)             500200    ['input_1[0][0]']             \n","                                                                                                  \n"," sine_position_encoding (Si  (None, None, 50)             0         ['embedding[0][0]']           \n"," nePositionEncoding)                                                                              \n","                                                                                                  \n"," tf.__operators__.add (TFOp  (None, None, 50)             0         ['embedding[0][0]',           \n"," Lambda)                                                             'sine_position_encoding[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," multi_head_attention (Mult  (None, None, 50)             101550    ['tf.__operators__.add[0][0]',\n"," iHeadAttention)                                                     'tf.__operators__.add[0][0]']\n","                                                                                                  \n"," add (Add)                   (None, None, 50)             0         ['tf.__operators__.add[0][0]',\n","                                                                     'multi_head_attention[0][0]']\n","                                                                                                  \n"," layer_normalization (Layer  (None, None, 50)             100       ['add[0][0]']                 \n"," Normalization)                                                                                   \n","                                                                                                  \n"," dense (Dense)               (None, None, 50)             2550      ['layer_normalization[0][0]'] \n","                                                                                                  \n"," add_1 (Add)                 (None, None, 50)             0         ['layer_normalization[0][0]', \n","                                                                     'dense[0][0]']               \n","                                                                                                  \n"," layer_normalization_1 (Lay  (None, None, 50)             100       ['add_1[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," dense_1 (Dense)             (None, None, 50)             2550      ['layer_normalization_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dense_2 (Dense)             (None, None, 10004)          510204    ['dense_1[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 1117254 (4.26 MB)\n","Trainable params: 617054 (2.35 MB)\n","Non-trainable params: 500200 (1.91 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["# WORD + POSITION EMBEDDING\n","input_layer = tf.keras.layers.Input(shape=(None,))\n","word_embedding = tf.keras.layers.Embedding(10004, 50, embeddings_initializer = tf.keras.initializers.constant(embedding_matrix), trainable=False, mask_zero=True)(input_layer)\n","position_embedding = keras_nlp.layers.SinePositionEncoding()(word_embedding)\n","word_and_position_embedding = word_embedding + position_embedding # taking output of these two layers and element wise adds them\n","# ATTENTION\n","attention = tf.keras.layers.MultiHeadAttention(10, 50)(word_and_position_embedding, word_and_position_embedding, use_causal_mask=True) # one for query, the other for key (keys and value the same so no need third), causal mask: since we give the model the entire sentence at a time, we want it to not have access to words in the future at a given position in a sentence. So we use this mask to mask out words ahead so the self attention cannot look ahead\n","residual = tf.keras.layers.Add()([word_and_position_embedding, attention])\n","normalize = tf.keras.layers.LayerNormalization()(residual)\n","# DENSE\n","dense = tf.keras.layers.Dense(50, activation=\"relu\")(normalize)\n","residual_dense = tf.keras.layers.Add()([normalize, dense])\n","normalize_dense = tf.keras.layers.LayerNormalization()(residual_dense)\n","\n","# OUTPUT\n","linear = tf.keras.layers.Dense(50, activation=None)(normalize_dense)\n","output_layer = tf.keras.layers.Dense(10004, activation=\"softmax\")(linear)\n","\n","model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n","model.summary()"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"w6pKLeIgNNXs","executionInfo":{"status":"ok","timestamp":1699636275728,"user_tz":300,"elapsed":182,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[],"source":["y=np.roll(x_all_padded, -1, 1)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"zYnX3btMNNXs","executionInfo":{"status":"ok","timestamp":1699636275870,"user_tz":300,"elapsed":144,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}}},"outputs":[],"source":["model.compile(\n","    optimizer=\"adam\",\n","    loss=\"sparse_categorical_crossentropy\"\n",")"]},{"cell_type":"code","source":["model.fit(x=x_all_padded, y=y, epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdhFeMO1NWef","executionInfo":{"status":"ok","timestamp":1699636889821,"user_tz":300,"elapsed":613954,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"a5b5376c-b14b-401f-abce-b039254ec57e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1085/1085 [==============================] - 74s 55ms/step - loss: 3.7208\n","Epoch 2/10\n","1085/1085 [==============================] - 64s 59ms/step - loss: 3.3186\n","Epoch 3/10\n","1085/1085 [==============================] - 59s 54ms/step - loss: 3.2295\n","Epoch 4/10\n","1085/1085 [==============================] - 62s 57ms/step - loss: 3.1808\n","Epoch 5/10\n","1085/1085 [==============================] - 60s 55ms/step - loss: 3.1502\n","Epoch 6/10\n","1085/1085 [==============================] - 59s 55ms/step - loss: 3.1290\n","Epoch 7/10\n","1085/1085 [==============================] - 59s 54ms/step - loss: 3.1131\n","Epoch 8/10\n","1085/1085 [==============================] - 61s 56ms/step - loss: 3.1006\n","Epoch 9/10\n","1085/1085 [==============================] - 58s 54ms/step - loss: 3.0903\n","Epoch 10/10\n","1085/1085 [==============================] - 58s 54ms/step - loss: 3.0819\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x79e922bcb130>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## Generate predictions"],"metadata":{"id":"ILyzLNmwNbro"}},{"cell_type":"code","source":["K=500 # number of things we're looking for -> 5 most likely words\n","result = [1] # 1 = [START]\n","for i in range(20):\n","  prediction = model.predict([np.asarray([result])])\n","  last_token_probability = prediction[0][-1]\n","  topK = np.argpartition(last_token_probability, -K)[-K:] # dirty sort such that last 5 (index from -1) are most likely, though not necessarily in order\n","  topK = np.delete(topK, np.where(topK==2))\n","  topKp = last_token_probability[topK] / np.sum(last_token_probability[topK]) # to get them back to proper probabilities withiin the 5\n","  result.append(np.random.choice(topK, p=topKp))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0uNGYC2NbcK","executionInfo":{"status":"ok","timestamp":1699637063017,"user_tz":300,"elapsed":1585,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"2f08d69d-0a00-4a60-9fae-a5dfc305fee0"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n"]}]},{"cell_type":"code","source":["decode(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"UWoOV2wDPJXp","executionInfo":{"status":"ok","timestamp":1699637064602,"user_tz":300,"elapsed":126,"user":{"displayName":"Chu Yi Chang","userId":"15940190556450135309"}},"outputId":"2495c763-bcd1-4e98-c8ea-bb22c2593927"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[START] i had seen this a terrible piece of watching this which a group in a number of my life so'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}